{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>CS 6476: Computer Vision, Fall 2019</h1>\n",
    "    <h1>PS3</h1>\n",
    "    <h3>Instructor: Devi Parikh</h3>\n",
    "    <h3>Due: Wednesday, October 8th, 11:59 pm</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Implement all of the functions described in this notebook. Then, apply the functions to generate mosaics of the provided images and some of your own.\n",
    "\n",
    "**When you are done save this notebook with the images and mosaics clearly visible.**\n",
    "\n",
    "Submit the notebook and other deliverables on Gradescope in the `PS3 Code` assignment (see the checklist below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Programming: Image Mosaics [100 points]\n",
    "\n",
    "In this exercise, you will implement an image stitcher that uses image warping and homographies to auto- matically create an image mosaic. We will focus on the case where we have two input images that should form the mosaic, where we warp one image into the plane of the second image and display the combined views. This problem will give some practice manipulating homogeneous coordinates, computing homography matrices, and performing image warps. For simplicity, we’ll specify corresponding pairs of points manually using mouse clicks. For extra credit, you can optionally implement an automated correspondence process with local feature matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python hints:**\n",
    "1. Useful Modules: `numpy`, `scipy`, `imageio`, `matplotlib`\n",
    "2. Useful Functions: `numpy.linalg.eig`, `numpy.linalg.inv`, `numpy.tile`, `numpy.meshgrid` \n",
    "3. There are some Python libraries that could do much of the work for this project. However, to get practice with how the algorithms work, we want you to write your own code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting Correspondences\n",
    "\n",
    "Implement the `pick_points` function in `pick-points.py` (included in the zip). The function should allow a user to manually identified corresponding points from two views. Hint: look up **matplotlib event handling** and the **matplotlib.widgets.Cursor** class.\n",
    "\n",
    "The results will be sensitive to the accuracy of the corresponding points; when providing clicks, choose distinctive points in the image that appear in both views.\n",
    "\n",
    "To use `pick-points.py` run:\n",
    "\n",
    "```bash\n",
    "# general usage:\n",
    "python3 pick-points.py <path/to/image1.jpg> <path/to/image2.jpg>\n",
    "\n",
    "# for example\n",
    "python3 pick-points.py wdc1.jpg wdc2.jpg\n",
    "```\n",
    "\n",
    "The selected points will be saved to `<path/to/image1.npy>` and `<path/to/image2.npy>`.\n",
    "\n",
    "*Include `pick-points.py` in your submission.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#############################################################################\n",
    "# TODO: Add additional imports\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Computing the Homography Parameters [20 points]\n",
    "\n",
    "Implement the `compute_homography(t1, t2)` function as described below.\n",
    "\n",
    "Be sure to handle homogenous and non-homogenous coordinates correctly. Look at the notes on how to estimate a homography [here](https://gatech.box.com/shared/static/yl4t92swxn4ffa928cec4lfz22csk86t.pdf).\n",
    "\n",
    "> Note: Your estimation procedure may perform better if image coordinates range from 0 to 2. Consider scaling your measurements to avoid numerical issues.\n",
    "\n",
    "**Manually export your function into a file named `compute_homography.py`. Add (only) the required imports and submit this file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(t1, t2):\n",
    "    \"\"\"\n",
    "    Computes the Homography matrix for corresponding image points t1 and t2\n",
    "\n",
    "    The function should take a list of N ≥ 4 pairs of corresponding points \n",
    "    from the two views, where each point is specified with its 2d image \n",
    "    coordinates.\n",
    "\n",
    "    Inputs:\n",
    "    - t1: Nx2 matrix of image points from view 1\n",
    "    - t2: Nx2 matrix of image points from view 2\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - H: 3x3 Homography matrix\n",
    "    \"\"\"\n",
    "    H = np.eye(3)\n",
    "    #############################################################################\n",
    "    # TODO: Compute the Homography matrix H for corresponding image points t1, t2\n",
    "    #############################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the homography matrix your function computed is correct by mapping the clicked image points from one view to the other, and displaying them on top of each respective image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Verify Homography matrix\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Warping Between Image Planes [30 points]\n",
    "\n",
    "Write a function `warp_image, merge_image = warp_image(input_image, ref_image, H)` which takes as input an image `input_image`, a reference image `ref_image`, and a 3x3 homography matrix `H`, and returns 2 images as outputs. The first output image, `warp_image`, should be the the input image `input_image` warped according to `H` to be in the frame of the reference image `ref_image`. The second output image, `merge_image`, should be a single mosaic image with a larger field of view containing both the input images. *Note: the output images will have a different shape than the input images.*\n",
    "\n",
    "To avoid holes, use an *inverse warp*. Calculate the bounding box in the reference frame of the destination image by warping all of the points from the source image into the reference frame of the destination. Then, sample all of the points in that bounding box from the proper coordinates in the source image.\n",
    "\n",
    "Once you have the input image warped into the reference image’s frame of reference, create a merged image showing the mosaic. Create a new image large enough to hold both the views; overlay one view onto the other, simply leaving it black wherever no data is available. Don’t worry about artifacts that result at the boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_image(input_image, ref_image, H):\n",
    "    \"\"\"\n",
    "    Warps and merges an input image onto the reference image. \n",
    "\n",
    "    Inputs:\n",
    "    - input_image: input image\n",
    "    - ref_image: reference image\n",
    "    - H: 3x3 homography matrix\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - warp_image: The input image warped according to H.\n",
    "    - merge_image: A single mosaic image containing both of the input images.\n",
    "    \"\"\"\n",
    "    warp_image, merge_image = None, None\n",
    "    #############################################################################\n",
    "    # TODO: Compute the Homography matrix H for corresponding image points t1, t2\n",
    "    #############################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return warp_image, merge_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply System to Provided Images [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Apply System to crop1.jpg and crop2.jpg\n",
    "\n",
    "Apply your system to `crop1.jpg` and `crop2.jpg` using the corresponding points `cc1.npy` and `cc2.npy`. The images and points are included in the zip file.\n",
    "\n",
    "*Display the warped and mosaic images in this notebook. Make sure both images are visible when you save (and submit) the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Apply system to Pair 1\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Apply System to wdc1.jpg and wdc2.jpg\n",
    "\n",
    "Apply your system to `wdc1.jpg` and `wdc2.jpg` using an appropriate choice of (manually selected) corresonding points. Only the images are included in the zip file.\n",
    "\n",
    "*Display the warped and mosaic images in this notebook. Make sure both images are visible when you save (and submit) the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Apply system to Pair 2\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Custom Mosaic [20 points]\n",
    "Show one additional example of a mosaic you create using images that you have taken. You might make a mosaic from two or more images of a broad scene that requires a wide angle view to see well. Or, make a mosaic using two images from the same room where the same person appears in both.\n",
    "\n",
    "*Display the original images and the mosaic in this notebook. Make sure all of the images are visible when you save (and submit) the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Apply system to create a custom mosaic\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Custom Warp [15 points]\n",
    "\n",
    "Warp one image into a frame region in the second image. To do this, let the points from the one view be the corners of the image you want to insert in the frame, and let the corresponding points in the second view be the clicked points of the frame (rectangle) into which the first image should be warped. Use this idea to replace one surface in an image with an image of something else. For example – overwrite a billboard with a picture of your dog, or project a drawing from one image onto the street in another image, or replace a portrait on the wall with someone else’s face, or paste a Powerpoint slide onto a movie screen, etc.\n",
    "\n",
    "*Display the original images and the mosaic in this notebook. Make sure all of the images are visible when you save (and submit) the notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Apply system to create a custom warp\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 [OPTIONAL] Extra Credit [up to 10 points each, max 30 points]\n",
    "\n",
    "Add as any more cells as needed to implement the following. Please include all implementation and results in the final submission to be considered for extra credit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Automatic Interest Point Detection + Local Feature Matching\n",
    "\n",
    "Replace the manual correspondence stage with automatic interest point detection and local feature matching. Check out available code here to compute the local interest points and features:\n",
    "\n",
    "[http://www.vlfeat.org/overview/sift.html](http://www.vlfeat.org/overview/sift.html)\n",
    "\n",
    "[http://www.robots.ox.ac.uk/~vgg/research/affine/detectors.html](http://www.robots.ox.ac.uk/~vgg/research/affine/detectors.html)\n",
    "\n",
    "*Display the automatically detected and matched points in this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RANSAC\n",
    "Implement RANSAC for robustly estimating the homography matrix from noisy correspondences. Show with an example where it successfully gives good results even when there are outlier (bad) corre- spondences given as input. Compare the robust output to the original (non-RANSAC) implementation where all correspondences are used.\n",
    "\n",
    "*Display the original images and results in this notebook. Make sure all of the images are visibel when you save (and submit) the notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rectification \n",
    "\n",
    "Rectify an image with some known planar surface (say, a square floor tile, or the rectangular face of a building facade) and show the virtual fronto-parallel view. In this case there is only one input image. To solve for H, you define the correspondences by clicking on the four corners of the planar surface in the input image, and then associating them with hand-specified coordinates for the output image. For example, a square tile’s corners from the non-frontal view could get mapped to [0 0; 0 N; N 0; N N] in the output.\n",
    "\n",
    "*Display the original and rectified images in this notebook. Make sure both images are visible when you save (and submit) the notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Short Video\n",
    "Make a short video in the style of the [HP commercial](https://www.youtube.com/watch?v=2RPl5vPEoQk)’s video which you saw in class. Building on #3 above, let the frame in the output video move to different positions over time, and warp the framed image into the correct position for every video frame in the sequence.\n",
    "\n",
    "*Name the video `ps3-extra-credit.mp4` and submit it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Deliverable Checklist\n",
    "\n",
    "- [ ] `ps3.ipynb`\n",
    "- [ ] `compute_homography.py`\n",
    "- [ ] `pick-points.py`\n",
    "- [ ] [extra credit] `ps3-extra-credit.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
